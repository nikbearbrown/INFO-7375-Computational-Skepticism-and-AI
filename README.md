# INFO 7375 Computational Skepticism and AI

## Course Prerequisites
- Instructor Approval: None
- Programming Background: A strong foundation in programming is necessary.
- Independent Research: Commitment to conducting independent research is expected.

## Course Description
In the age of artificial intelligence, computational models play an increasingly vital role in decision-making across various domains. However, their reliability and transparency remain critical concerns. This course explores computational methods for data validation and critical thinking to enhance trust in AI models.

Through research and practical applications, students will develop systems and methodologies to:
- Critically assess AI outputs
- Identify biases in AI systems
- Validate machine learning models

The course emphasizes systematic doubt and continuous validation of AI using computational techniques such as:
- Probability
- Deep learning
- Reinforcement learning
- Machine learning
- Data visualization

## Learning Objectives & Modules

### Module 1: Foundations of Computational Skepticism
* **Philosophical Foundations:** Skepticism in philosophy (Descartes, Hume, Popper).
* **Critical Thinking in AI:** Why trust AI? How does it compare to human reasoning?
* **Key Concepts:** Epistemology in AI—How do we "know" what we know when AI makes decisions?
* **Hands-on:** Analyzing real-world AI failures.

**CASE STUDY: The Medical Diagnosis Assistant**  
Students will examine a real-world AI system designed to assist doctors with diagnoses that produced high accuracy in lab tests but performed inconsistently in clinical settings. Students will:
- Analyze where the AI system's reasoning diverged from medical experts
- Trace model decision paths to identify logical fallacies
- Compare the AI's confidence levels with actual performance
- Develop a framework to validate the system's recommendations against established medical protocols

### Module 2: Data Validation Techniques for AI Systems
* **Philosophical Foundations:** Truth and falsifiability in data-driven conclusions.
* **Critical Thinking in AI:** Can data ever be truly objective?
* **Key Concepts:** Plato's Allegory of the Cave—Are datasets just shadows of reality?
* **Hands-on:** Exploratory Data Analysis (EDA) to uncover hidden dataset assumptions.

**CASE STUDY: Financial Fraud Detection System**  
Students will work with anonymized banking transaction data to improve a fraud detection system that suffers from high false positive rates. Students will:
- Perform comprehensive EDA to identify hidden patterns and anomalies in the dataset
- Develop validation pipelines to verify data integrity and representativeness
- Implement statistical tests to challenge the assumptions in the model
- Create a monitoring system to track data drift and concept drift over time

### Module 3: Bias Detection and Mitigation in AI
* **Philosophical Foundations:** Implicit bias and cognitive bias in shaping AI models.
* **Critical Thinking in AI:** Do AI models reinforce existing power structures?
* **Key Concepts:** Postmodernism and AI—Does AI reflect truth or our own biases?
* **Hands-on:** Identifying and mitigating bias in real-world AI datasets.

**CASE STUDY: Hiring Algorithm Audit**  
Students will analyze a hiring recommendation algorithm used by a major corporation that showed disparate impact across demographic groups. Students will:
- Conduct intersectional analysis to identify where biases emerge in the pipeline
- Implement fairness metrics and visualizations to quantify discrimination
- Develop bias mitigation strategies while maintaining algorithm performance
- Create an ethical framework for ongoing algorithmic auditing

### Module 4: Explainability and Interpretability of AI Models
* **Philosophical Foundations:** The Black Box Problem—Is understanding necessary for trust?
* **Critical Thinking in AI:** Does it matter if we don't know how AI makes good predictions?
* **Key Concepts:** Wittgenstein's language games—Are AI explanations meaningful or tricks?
* **Hands-on:** Implementing SHAP and LIME explanations.

**CASE STUDY: Credit Approval Transparency System**  
Students will work with a black-box credit scoring model that needs to comply with regulations requiring explanations for denial decisions. Students will:
- Implement SHAP and LIME techniques to explain individual decisions
- Develop counterfactual explanations to provide actionable feedback
- Create a user-friendly dashboard for credit officers to interpret model decisions
- Evaluate the effectiveness of explanations with real users

### Module 5: Probabilistic Reasoning and Uncertainty in AI
* **Philosophical Foundations:** Hume's Problem of Induction—Can we trust AI predictions?
* **Critical Thinking in AI:** Are probabilities meaningful, or just human-made tools?
* **Key Concepts:** Bayesian vs. Frequentist probability.
* **Hands-on:** Using probability distributions to assess AI confidence levels.

**CASE STUDY: Climate Risk Assessment Tool**  
Students will enhance an AI system used by insurance companies to assess property risk from climate events. Students will:
- Implement proper uncertainty quantification in predictions
- Develop calibrated confidence intervals for different risk scenarios
- Create visualizations showing the distribution of possible outcomes
- Build a decision support system that appropriately represents uncertainty

### Module 6: Adversarial Attacks and Robust AI Systems
* **Philosophical Foundations:** Deception in AI—Can AI be "fooled"?
* **Critical Thinking in AI:** If AI can be tricked, does it truly "understand"?
* **Key Concepts:** Nietzsche and AI—"Will to power" meets adversarial attacks.
* **Hands-on:** Designing adversarial attacks and defense mechanisms.

**CASE STUDY: Autonomous Vehicle Safety**  
Students will test and improve the robustness of computer vision systems used in autonomous vehicles. Students will:
- Design adversarial attacks that could confuse traffic sign recognition
- Implement defense mechanisms against weather and lighting condition variations
- Develop robustness testing protocols for vision systems
- Create a certification framework for minimum safety standards

### Module 7: Reinforcement Learning for AI Reliability
* **Philosophical Foundations:** Free will vs. determinism—Do AI agents "choose"?
* **Critical Thinking in AI:** Can AI develop ethical decision-making?
* **Key Concepts:** Utilitarianism in AI—Optimizing rewards vs. ethical outcomes.
* **Hands-on:** Implementing reinforcement learning models.

**CASE STUDY: Supply Chain Optimization**  
Students will work with a reinforcement learning system designed to optimize inventory management that works well in simulation but struggles with real-world variability. Students will:
- Identify gaps between simulation and real-world performance
- Implement robust RL algorithms that account for uncertainty
- Develop a system that adapts to unexpected supply chain disruptions
- Create evaluation metrics that balance short-term efficiency with long-term reliability

### Module 8: Data Visualization for AI Transparency
* **Philosophical Foundations:** The role of perception in understanding AI decisions.
* **Critical Thinking in AI:** Can visualizations mislead us?
* **Key Concepts:** McLuhan's "The medium is the message"—How dashboards shape AI trust.
* **Hands-on:** Designing AI transparency visualizations.

**CASE STUDY: Public Health Monitoring Dashboard**  
Students will improve a COVID-19 prediction dashboard used by public health officials that needs to effectively communicate uncertainty and model limitations. Students will:
- Design interactive visualizations that accurately represent model confidence
- Implement user testing to ensure visualizations aren't misleading
- Create a tiered information system for different stakeholder needs
- Develop a framework for communicating AI limitations to non-technical users

### Module 9: Ethical Considerations and AI Governance
* **Philosophical Foundations:** Kant's categorical imperative—Should AI follow universal ethics?
* **Critical Thinking in AI:** Who is accountable for AI decisions?
* **Key Concepts:** AI as an existential risk—Bostrom's views on superintelligence.
* **Hands-on:** Case studies on AI ethics violations and governance strategies.

**CASE STUDY: Social Media Content Moderation**  
Students will examine an AI content moderation system that struggled with cultural context and free speech boundaries. Students will:
- Analyze real incidents where the system made controversial decisions
- Develop a governance framework with appropriate human oversight
- Create an appeal process for contested AI decisions
- Implement ethical guidelines for balancing competing values

### Module 10: Final Project & Research Presentations
* **Philosophical Foundations:** The Socratic method—Using questioning to refine research.
* **Critical Thinking in AI:** How do we truly validate AI systems?
* **Key Concepts:** AI as a tool vs. AI as an agent.
* **Hands-on:** Presenting research on AI validation methodologies.

**CASE STUDY: Student-Selected Real-World AI Validation Challenge**  
Students will select an actual AI system currently deployed in industry or government and:
- Conduct a comprehensive validation audit
- Develop a custom validation toolkit specific to the domain
- Create a roadmap for ongoing monitoring and improvement
- Present findings and recommendations as if to the organization's leadership

## Course Highlights
✅ Philosophy Meets Computation – Explore the intersection of philosophy, logic, and AI, developing a critical perspective on AI's role in society.
✅ Hands-on Data Validation – Work with real-world datasets to identify biases, inconsistencies, and errors. Build automated AI validation pipelines.
✅ Explainable AI & Model Transparency – Learn techniques such as SHAP, LIME, and counterfactual explanations to interpret AI decisions.
✅ Bias Detection & Ethical AI Development – Examine AI bias and explore mitigation strategies. Engage in discussions on AI governance.
✅ Adversarial AI & Robust Systems – Study adversarial attacks on AI and develop techniques to defend against them.
✅ Reinforcement Learning & AI Reliability – Implement reinforcement learning strategies to create adaptable AI systems.
✅ Data Visualization for AI Trust – Develop interactive dashboards and visualization techniques to communicate AI performance effectively.
✅ Critical Thinking & AI Skepticism – Use logical reasoning, probabilistic thinking, and philosophical analysis to improve AI reliability.
✅ Interdisciplinary Approach – Merge AI with cognitive science, philosophy, and ethics for a holistic understanding of AI validation.
✅ Research-Oriented Learning – Conduct independent research projects, present findings, and collaborate with peers.

## Project Component
Students will select a subproject within the first two weeks, aligning with their background and interests, to develop AI validation tools and methodologies.

- Project Approval: Based on expertise in probability, deep learning, reinforcement learning, machine learning, or data visualization.
- Resources: Current projects and code repositories are maintained on the INFO 7375 GitHub repository.
- Presentations: Students will present research updates every two to three weeks.

## Learning Outcomes
By the end of this course, students will:
✔ Develop computational frameworks for systematic data validation and AI model verification.
✔ Gain expertise in critical thinking methodologies applied to AI and machine learning.
✔ Conduct original research in AI validation, leading to professional-quality papers and projects.
✔ Recognize and mitigate common biases and errors in AI models.
✔ Enhance their ability to critique AI systems constructively and contribute to the broader research community.

## Course Materials
**Textbook**
- 📖 Title: Computational Skepticism for AI by Nik Bear Brown (Free Online)
- 📖 Publisher: Bear Brown & Company, LLC
- 📖 Publication Date: May 2025
- 📖 ISBN: [To Be Announced]

**Additional Resources**
- Academic papers on AI validation
- AI research reports
- Articles on prompt engineering & Generative AI
- Case study datasets and code repositories
- Industry reports on AI failures and successes
- AI validation toolkits and frameworks
- Hands-on tutorials for each case study

By the end of the course, students will master AI validation techniques, prompt engineering, and fine-tuning LLMs, equipping them to navigate AI-driven creativity and problem-solving across diverse fields.
